# nanochat é¡¹ç›®æŠ€æœ¯æ–‡æ¡£

> **ç‰ˆæœ¬**: v0.1.0  
> **æœ€åæ›´æ–°**: 2025å¹´11æœˆ  
> **æ–‡æ¡£ç±»å‹**: ä¿å§†çº§æŠ€æœ¯æ–‡æ¡£

---

## ğŸ“‹ ç›®å½•

- [ä¸€ã€é¡¹ç›®æ¦‚è¿°](#ä¸€é¡¹ç›®æ¦‚è¿°)
- [äºŒã€æ ¸å¿ƒæ¶æ„è¯¦è§£](#äºŒæ ¸å¿ƒæ¶æ„è¯¦è§£)
- [ä¸‰ã€æ¨¡å—åŠŸèƒ½è¯¦è§£](#ä¸‰æ¨¡å—åŠŸèƒ½è¯¦è§£)
- [å››ã€è®­ç»ƒæµç¨‹è¯¦è§£](#å››è®­ç»ƒæµç¨‹è¯¦è§£)
- [äº”ã€ä½¿ç”¨æŒ‡å—](#äº”ä½¿ç”¨æŒ‡å—)
- [å…­ã€æ€»ç»“ä¸æœ€ä½³å®è·µ](#å…­æ€»ç»“ä¸æœ€ä½³å®è·µ)

> ğŸ’¡ **è¡¥å……é˜…è¯»**ï¼š
> - [è®­ç»ƒå‚æ•°è®¡ç®—è¯¦è§£](./è®­ç»ƒå‚æ•°è®¡ç®—è¯¦è§£.md) - æ·±å…¥è§£æå„ä¸ªè®­ç»ƒå‚æ•°å¦‚ä½•è®¡ç®—å’Œç›¸äº’å½±å“
> - [æ¨¡å‹è§„æ¨¡ä¸ä¸­æ–‡è¯­æ–™é€‚é…æŒ‡å—](./æ¨¡å‹è§„æ¨¡ä¸ä¸­æ–‡è¯­æ–™é€‚é…æŒ‡å—.md) - d4-d32 å„è§„æ¨¡å‚æ•°è¯¦è§£ä¸ä¸­æ–‡/ä¸­è‹±æ–‡è®­ç»ƒç­–ç•¥

---

## ä¸€ã€é¡¹ç›®æ¦‚è¿°

### 1.1 é¡¹ç›®ç®€ä»‹

**nanochat** æ˜¯ä¸€ä¸ªå®Œæ•´çš„ç«¯åˆ°ç«¯ LLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰å®ç°é¡¹ç›®ï¼Œæ—¨åœ¨ç”¨ **100 ç¾å…ƒ**çš„é¢„ç®—è®­ç»ƒå‡ºä¸€ä¸ªç±»ä¼¼ ChatGPT çš„èŠå¤©æ¨¡å‹ã€‚è¿™æ˜¯ä¸€ä¸ªç²¾ç®€ã€æ¸…æ™°ã€å¯ç ´è§£çš„ä»£ç åº“ï¼Œè®¾è®¡ç”¨äºåœ¨å•ä¸ª 8XH100 GPU èŠ‚ç‚¹ä¸Šè¿è¡Œå®Œæ•´çš„è®­ç»ƒæµç¨‹ã€‚

**æ ¸å¿ƒç‰¹ç‚¹**ï¼š
- ğŸ¯ **å…¨æ ˆå®ç°**ï¼šæ¶µç›–åˆ†è¯ã€é¢„è®­ç»ƒã€å¾®è°ƒã€è¯„ä¼°ã€æ¨ç†å’Œ Web æœåŠ¡
- ğŸ’° **æˆæœ¬å¯æ§**ï¼š$100ï¼ˆ4å°æ—¶ï¼‰åˆ° $1000ï¼ˆçº¦42å°æ—¶ï¼‰çš„ä¸åŒè§„æ¨¡è®­ç»ƒæ–¹æ¡ˆ
- ğŸ”§ **æç®€è®¾è®¡**ï¼šçº¦ 8,300 è¡Œä»£ç ï¼Œ45 ä¸ªæ–‡ä»¶ï¼Œä¾èµ–æœ€å°åŒ–
- ğŸ“š **æ•™å­¦å¯¼å‘**ï¼šä½œä¸º Eureka Labs çš„ LLM101n è¯¾ç¨‹é¡¶ç‚¹é¡¹ç›®
- ğŸš€ **é«˜æ€§èƒ½**ï¼šä½¿ç”¨ Muon ä¼˜åŒ–å™¨å’Œ PyTorch ç¼–è¯‘åŠ é€Ÿ

**æŠ€æœ¯äº®ç‚¹**ï¼š
- GPT æ¶æ„å®ç°ï¼ˆå« RoPEã€QK Normã€ReLUÂ²ã€MQA/GQAï¼‰
- è‡ªå®šä¹‰ Rust BPE åˆ†è¯å™¨ï¼ˆé«˜æ•ˆè®­ç»ƒå’Œæ¨ç†ï¼‰
- åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒï¼ˆDDPï¼‰
- KV Cache æ¨ç†å¼•æ“
- å·¥å…·è°ƒç”¨èƒ½åŠ›ï¼ˆPython REPLï¼‰
- å¼ºåŒ–å­¦ä¹ æ”¯æŒï¼ˆGRPO ç®—æ³•ï¼‰

### 1.2 é¡¹ç›®ç»“æ„æ€»è§ˆ

```
nanochat/
â”œâ”€â”€ nanochat/              # æ ¸å¿ƒåº“ä»£ç 
â”‚   â”œâ”€â”€ gpt.py            # GPT æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ engine.py         # æ¨ç†å¼•æ“ï¼ˆå« KV Cacheï¼‰
â”‚   â”œâ”€â”€ dataloader.py     # åˆ†å¸ƒå¼æ•°æ®åŠ è½½å™¨
â”‚   â”œâ”€â”€ tokenizer.py      # BPE åˆ†è¯å™¨å°è£…
â”‚   â”œâ”€â”€ adamw.py          # åˆ†å¸ƒå¼ AdamW ä¼˜åŒ–å™¨
â”‚   â”œâ”€â”€ muon.py           # Muon ä¼˜åŒ–å™¨
â”‚   â”œâ”€â”€ checkpoint_manager.py  # æ£€æŸ¥ç‚¹ç®¡ç†
â”‚   â”œâ”€â”€ configurator.py   # é…ç½®ç®¡ç†ç³»ç»Ÿ
â”‚   â”œâ”€â”€ common.py         # é€šç”¨å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ dataset.py        # é¢„è®­ç»ƒæ•°æ®ä¸‹è½½å·¥å…·
â”‚   â”œâ”€â”€ core_eval.py      # CORE è¯„ä¼°æŒ‡æ ‡
â”‚   â”œâ”€â”€ loss_eval.py      # æŸå¤±è¯„ä¼°ï¼ˆbits per byteï¼‰
â”‚   â”œâ”€â”€ execution.py      # å·¥å…·æ‰§è¡Œï¼ˆPython REPLï¼‰
â”‚   â”œâ”€â”€ report.py         # æŠ¥å‘Šç”Ÿæˆå·¥å…·
â”‚   â””â”€â”€ ui.html           # Web UI ç•Œé¢
â”œâ”€â”€ scripts/              # å¯æ‰§è¡Œè„šæœ¬
â”‚   â”œâ”€â”€ tok_train.py      # åˆ†è¯å™¨è®­ç»ƒ
â”‚   â”œâ”€â”€ tok_eval.py       # åˆ†è¯å™¨è¯„ä¼°
â”‚   â”œâ”€â”€ base_train.py     # åŸºç¡€æ¨¡å‹é¢„è®­ç»ƒ
â”‚   â”œâ”€â”€ base_eval.py      # åŸºç¡€æ¨¡å‹è¯„ä¼°
â”‚   â”œâ”€â”€ base_loss.py      # åŸºç¡€æ¨¡å‹æŸå¤±è®¡ç®—
â”‚   â”œâ”€â”€ mid_train.py      # ä¸­é—´è®­ç»ƒï¼ˆå¯¹è¯æ ¼å¼é€‚åº”ï¼‰
â”‚   â”œâ”€â”€ chat_sft.py       # ç›‘ç£å¾®è°ƒ
â”‚   â”œâ”€â”€ chat_rl.py        # å¼ºåŒ–å­¦ä¹ 
â”‚   â”œâ”€â”€ chat_eval.py      # èŠå¤©æ¨¡å‹è¯„ä¼°
â”‚   â”œâ”€â”€ chat_cli.py       # å‘½ä»¤è¡ŒèŠå¤©ç•Œé¢
â”‚   â””â”€â”€ chat_web.py       # Web èŠå¤©ç•Œé¢
â”œâ”€â”€ tasks/                # è¯„ä¼°ä»»åŠ¡å®šä¹‰
â”‚   â”œâ”€â”€ common.py         # ä»»åŠ¡åŸºç±»
â”‚   â”œâ”€â”€ arc.py            # ARC ç§‘å­¦é—®ç­”
â”‚   â”œâ”€â”€ gsm8k.py          # æ•°å­¦é—®é¢˜
â”‚   â”œâ”€â”€ humaneval.py      # ä»£ç è¯„ä¼°
â”‚   â”œâ”€â”€ mmlu.py           # å¤šé¢†åŸŸé€‰æ‹©é¢˜
â”‚   â”œâ”€â”€ smoltalk.py       # å¯¹è¯æ•°æ®é›†
â”‚   â”œâ”€â”€ spellingbee.py    # æ‹¼å†™ä»»åŠ¡
â”‚   â””â”€â”€ customjson.py     # è‡ªå®šä¹‰ JSON ä»»åŠ¡
â”œâ”€â”€ rustbpe/              # Rust å®ç°çš„ BPE åˆ†è¯å™¨
â”‚   â”œâ”€â”€ Cargo.toml        # Rust é¡¹ç›®é…ç½®
â”‚   â””â”€â”€ src/lib.rs        # Rust æºç 
â”œâ”€â”€ tests/                # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ dev/                  # å¼€å‘å·¥å…·
â”œâ”€â”€ speedrun.sh           # å¿«é€Ÿè®­ç»ƒè„šæœ¬ï¼ˆ$100 é¢„ç®—ï¼‰
â”œâ”€â”€ run1000.sh            # å®Œæ•´è®­ç»ƒè„šæœ¬ï¼ˆ$1000 é¢„ç®—ï¼‰
â””â”€â”€ pyproject.toml        # Python é¡¹ç›®é…ç½®
```

### 1.3 æŠ€æœ¯æ ˆ

**ç¼–ç¨‹è¯­è¨€**ï¼š
- Python 3.10+ï¼ˆä¸»è¦å®ç°ï¼‰
- Rustï¼ˆé«˜æ€§èƒ½åˆ†è¯å™¨ï¼‰
- HTML/CSS/JavaScriptï¼ˆWeb UIï¼‰

**æ ¸å¿ƒä¾èµ–**ï¼š
- PyTorch 2.8+ï¼ˆæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼‰
- tiktokenï¼ˆåˆ†è¯æ¨ç†ï¼‰
- tokenizersï¼ˆHuggingFace åˆ†è¯å™¨ï¼‰
- fastapi + uvicornï¼ˆWeb æœåŠ¡ï¼‰
- datasetsï¼ˆæ•°æ®é›†åŠ è½½ï¼‰
- wandbï¼ˆå®éªŒè·Ÿè¸ªï¼Œå¯é€‰ï¼‰

**æ„å»ºå·¥å…·**ï¼š
- uvï¼ˆPython åŒ…ç®¡ç†ï¼‰
- maturinï¼ˆRust-Python ç»‘å®šï¼‰
- cargoï¼ˆRust æ„å»ºå·¥å…·ï¼‰

---

## äºŒã€æ ¸å¿ƒæ¶æ„è¯¦è§£

### 2.1 æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     nanochat å®Œæ•´è®­ç»ƒæµç¨‹                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    é˜¶æ®µ 1: æ•°æ®å‡†å¤‡ä¸åˆ†è¯å™¨è®­ç»ƒ           â”‚
        â”‚  - ä¸‹è½½é¢„è®­ç»ƒæ•°æ®ï¼ˆFineWeb-Eduï¼‰         â”‚
        â”‚  - è®­ç»ƒ BPE åˆ†è¯å™¨ï¼ˆvocab_size=65536ï¼‰   â”‚
        â”‚  - è¯„ä¼°å‹ç¼©ç‡                            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    é˜¶æ®µ 2: åŸºç¡€æ¨¡å‹é¢„è®­ç»ƒ (Base)          â”‚
        â”‚  - åœ¨åŸå§‹æ–‡æœ¬ä¸Šè®­ç»ƒï¼ˆ20B tokensï¼‰         â”‚
        â”‚  - ä½¿ç”¨ Muon + AdamW ä¼˜åŒ–å™¨              â”‚
        â”‚  - è¯„ä¼° CORE æŒ‡æ ‡å’Œå›°æƒ‘åº¦                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    é˜¶æ®µ 3: ä¸­é—´è®­ç»ƒ (Midtraining)         â”‚
        â”‚  - å­¦ä¹ å¯¹è¯æ ¼å¼å’Œç‰¹æ®Š token               â”‚
        â”‚  - å¼•å…¥å·¥å…·ä½¿ç”¨èƒ½åŠ›                       â”‚
        â”‚  - æ··åˆå¤šé€‰é¢˜å’Œå¯¹è¯æ•°æ®                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    é˜¶æ®µ 4: ç›‘ç£å¾®è°ƒ (SFT)                 â”‚
        â”‚  - åœ¨é«˜è´¨é‡å¯¹è¯ä¸Šç²¾è°ƒ                     â”‚
        â”‚  - ä»»åŠ¡æ··åˆï¼šARC/GSM8K/SmolTalk          â”‚
        â”‚  - æ³¨å…¥èº«ä»½ä¸ªæ€§                          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    é˜¶æ®µ 5: å¼ºåŒ–å­¦ä¹  (RL, å¯é€‰)             â”‚
        â”‚  - GRPO ç®—æ³•ä¼˜åŒ–                         â”‚
        â”‚  - ä¸»è¦é’ˆå¯¹ GSM8K æ•°å­¦é—®é¢˜               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    é˜¶æ®µ 6: éƒ¨ç½²ä¸æ¨ç†                     â”‚
        â”‚  - CLI èŠå¤©ç•Œé¢                          â”‚
        â”‚  - Web UI æœåŠ¡                           â”‚
        â”‚  - KV Cache åŠ é€Ÿæ¨ç†                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ¨¡å‹æ¶æ„è®¾è®¡

**GPT æ¨¡å‹ç‰¹æ€§**ï¼ˆ`nanochat/gpt.py`ï¼‰ï¼š

1. **ä½ç½®ç¼–ç **ï¼šä½¿ç”¨ RoPEï¼ˆRotary Position Embeddingsï¼‰è€Œéä¼ ç»Ÿçš„ä½ç½®åµŒå…¥
2. **æ³¨æ„åŠ›æœºåˆ¶**ï¼šæ”¯æŒ MQAï¼ˆMulti-Query Attentionï¼‰å’Œ GQAï¼ˆGrouped-Query Attentionï¼‰
3. **å½’ä¸€åŒ–**ï¼šä½¿ç”¨æ— å‚æ•°çš„ RMSNorm
4. **æ¿€æ´»å‡½æ•°**ï¼šMLP ä½¿ç”¨ ReLUÂ² æ¿€æ´»
5. **ç¨³å®šæ€§æŠ€æœ¯**ï¼š
   - QK Normï¼ˆæŸ¥è¯¢å’Œé”®çš„å½’ä¸€åŒ–ï¼‰
   - Logits Softcapï¼ˆlogits è£å‰ªåˆ° [-15, 15]ï¼‰
6. **è§£è€¦æƒé‡**ï¼šToken åµŒå…¥å’Œ LM Head ä¸å…±äº«æƒé‡

**æ¨¡å‹è§„æ¨¡é…ç½®**ï¼š

```python
# depth=20 (d20) æ¨¡å‹ï¼Œçº¦ 561M å‚æ•°
depth = 20
model_dim = depth * 64 = 1280
num_heads = (model_dim + 127) // 128 = 10
head_dim = 128
vocab_size = 65536
sequence_len = 2048

# å‚æ•°è®¡ç®—
# - åµŒå…¥å±‚ï¼švocab_size Ã— model_dim
# - Transformer å±‚ï¼šdepth Ã— (æ³¨æ„åŠ› + MLP)
# - LM Headï¼šmodel_dim Ã— vocab_size
```

### 2.3 ä¼˜åŒ–å™¨è®¾è®¡

**æ··åˆä¼˜åŒ–å™¨ç­–ç•¥**ï¼ˆ`nanochat/muon.py` + `nanochat/adamw.py`ï¼‰ï¼š

```python
# 1. Muon ä¼˜åŒ–å™¨ - ç”¨äºçº¿æ€§å±‚æƒé‡çŸ©é˜µ
#    - åŸºäºç‰›é¡¿æ–¹æ³•çš„äºŒé˜¶ä¼˜åŒ–å™¨
#    - å­¦ä¹ ç‡ï¼š0.02
#    - åŠ¨é‡ï¼š0.85 -> 0.95ï¼ˆé€æ­¥å¢åŠ ï¼‰

# 2. AdamW ä¼˜åŒ–å™¨ - ç”¨äºåµŒå…¥å±‚å’Œ LM Head
#    - åµŒå…¥å±‚å­¦ä¹ ç‡ï¼š0.2ï¼ˆç¼©æ”¾ âˆ1/âˆšd_modelï¼‰
#    - LM Head å­¦ä¹ ç‡ï¼š0.004
#    - Betasï¼š(0.8, 0.95)
#    - æƒé‡è¡°å‡ï¼š0.0
```

**å­¦ä¹ ç‡è°ƒåº¦**ï¼š
- é¢„çƒ­ï¼ˆWarmupï¼‰ï¼š0% çš„è®­ç»ƒæ­¥æ•°
- æ’å®šæœŸï¼š80% çš„è®­ç»ƒæ­¥æ•°
- è¡°å‡æœŸï¼ˆWarmdownï¼‰ï¼š20% çš„è®­ç»ƒæ­¥æ•°ï¼Œçº¿æ€§è¡°å‡åˆ° 0

### 2.4 æ•°æ®å¤„ç†æµç¨‹

**é¢„è®­ç»ƒæ•°æ®**ï¼ˆ`nanochat/dataset.py` + `nanochat/dataloader.py`ï¼‰ï¼š

```
FineWeb-Edu (æ¥æº)
    â”‚
    â”œâ”€â†’ ä¸‹è½½ Parquet åˆ†ç‰‡ï¼ˆ~1822 ä¸ªåˆ†ç‰‡ï¼Œæ¯ä¸ª 250M å­—ç¬¦ï¼‰
    â”‚
    â”œâ”€â†’ æµå¼è¯»å–å’Œåˆ†è¯
    â”‚   - ä½¿ç”¨ deque ç¼“å†²åŒº
    â”‚   - æ‰¹é‡åˆ†è¯ï¼ˆbatch_size=128ï¼‰
    â”‚   - å¤šçº¿ç¨‹åŠ é€Ÿï¼ˆ4 çº¿ç¨‹ï¼‰
    â”‚
    â””â”€â†’ æ„é€ è®­ç»ƒæ‰¹æ¬¡
        - åºåˆ—é•¿åº¦ï¼š2048 tokens
        - æ‰¹æ¬¡å¤§å°ï¼š524,288 tokensï¼ˆæ€»è®¡ï¼‰
        - æ¢¯åº¦ç´¯ç§¯ï¼šè‡ªåŠ¨è®¡ç®—
```

**å¯¹è¯æ•°æ®æ ¼å¼**ï¼ˆ`nanochat/tokenizer.py::render_conversation`ï¼‰ï¼š

```
<|bos|>
<|user_start|>ç”¨æˆ·æ¶ˆæ¯å†…å®¹<|user_end|>
<|assistant_start|>åŠ©æ‰‹å›å¤å†…å®¹<|assistant_end|>
<|user_start|>ç»§ç»­å¯¹è¯...<|user_end|>
<|assistant_start|>ç»§ç»­å›å¤...<|assistant_end|>
```

**å·¥å…·è°ƒç”¨æ ¼å¼**ï¼š

```
<|assistant_start|>
æˆ‘æ¥å¸®ä½ è®¡ç®—ï¼š
<|python_start|>2 + 2<|python_end|>
<|output_start|>4<|output_end|>
ç»“æœæ˜¯ 4ã€‚
<|assistant_end|>
```

---

## ä¸‰ã€æ¨¡å—åŠŸèƒ½è¯¦è§£

### 3.1 æ ¸å¿ƒæ¨¡å—

#### 3.1.1 GPT æ¨¡å‹ï¼ˆ`nanochat/gpt.py`ï¼‰

**ç±»ç»“æ„**ï¼š

```python
GPTConfig:
    - sequence_len: int = 2048      # æœ€å¤§åºåˆ—é•¿åº¦
    - vocab_size: int = 65536       # è¯æ±‡è¡¨å¤§å°
    - n_layer: int = 20             # Transformer å±‚æ•°
    - n_head: int = 10              # æ³¨æ„åŠ›å¤´æ•°
    - n_kv_head: int = 10           # KV å¤´æ•°ï¼ˆMQA/GQAï¼‰
    - n_embd: int = 1280            # æ¨¡å‹ç»´åº¦

GPT(nn.Module):
    - transformer:
        - wte: Embedding            # Token åµŒå…¥
        - h: ModuleList[Block]      # Transformer å—
    - lm_head: Linear               # è¾“å‡ºæŠ•å½±
    - cos, sin: Tensor              # RoPE åµŒå…¥ï¼ˆç¼“å­˜ï¼‰
```

**å…³é”®æ–¹æ³•**ï¼š

1. **`forward(idx, targets=None, kv_cache=None)`**ï¼š
   - è®­ç»ƒæ—¶ï¼šè¿”å›äº¤å‰ç†µæŸå¤±
   - æ¨ç†æ—¶ï¼šè¿”å› logits
   - æ”¯æŒ KV Cache åŠ é€Ÿ

2. **`generate(tokens, max_tokens, temperature, top_k)`**ï¼š
   - æœ´ç´ çš„è‡ªå›å½’ç”Ÿæˆ
   - é€‚ç”¨äºç®€å•æ¨ç†

3. **`setup_optimizers(...)`**ï¼š
   - è‡ªåŠ¨é…ç½®æ··åˆä¼˜åŒ–å™¨
   - æ ¹æ®æ¨¡å‹ç»´åº¦ç¼©æ”¾å­¦ä¹ ç‡

4. **`estimate_flops()`**ï¼š
   - ä¼°ç®—æ¯ä¸ª token çš„ FLOPs
   - ç”¨äºè®¡ç®—è®­ç»ƒæ•ˆç‡ï¼ˆMFUï¼‰

**æ³¨æ„åŠ›æœºåˆ¶**ï¼ˆ`CausalSelfAttention`ï¼‰ï¼š

```python
# æ ‡å‡†æµç¨‹
Q = norm(RoPE(query_proj(x)))
K = norm(RoPE(key_proj(x)))
V = value_proj(x)

# KV Cache æ”¯æŒ
if kv_cache:
    K, V = kv_cache.insert_kv(layer_idx, K, V)

# Scaled Dot-Product Attention
out = F.scaled_dot_product_attention(Q, K, V, is_causal=True)
```

**MLP æ¨¡å—**ï¼š

```python
def forward(x):
    x = linear1(x)           # [B, T, D] -> [B, T, 4D]
    x = relu(x).square()     # ReLUÂ² æ¿€æ´»
    x = linear2(x)           # [B, T, 4D] -> [B, T, D]
    return x
```

#### 3.1.2 æ¨ç†å¼•æ“ï¼ˆ`nanochat/engine.py`ï¼‰

**KV Cache å®ç°**ï¼š

```python
class KVCache:
    # å½¢çŠ¶ï¼š(n_layers, 2, batch_size, n_heads, seq_len, head_dim)
    # - 2: K å’Œ V
    # - åŠ¨æ€å¢é•¿ï¼šæŒ‰éœ€æ‰©å±• seq_len ç»´åº¦ï¼ˆ1024 æ­¥é•¿ï¼‰
    
    def insert_kv(layer_idx, k, v):
        # æ’å…¥æ–°çš„ K/V åˆ°ç¼“å­˜
        # è¿”å›å®Œæ•´çš„å†å² K/Vï¼ˆä½œä¸ºè§†å›¾ï¼‰
        # è‡ªåŠ¨æ›´æ–° pos æŒ‡é’ˆ
```

**Engine ç”Ÿæˆæµç¨‹**ï¼š

```python
class Engine:
    def generate(tokens, num_samples, max_tokens, temperature, top_k):
        # 1. é¢„å¡«å……é˜¶æ®µï¼ˆPrefillï¼‰
        #    - å•æ‰¹æ¬¡å¤„ç†æç¤ºè¯
        #    - åˆå§‹åŒ– KV Cache
        
        # 2. å¤åˆ¶ KV Cache
        #    - ä¸ºæ¯ä¸ªæ ·æœ¬åˆ›å»ºç‹¬ç«‹çš„ç¼“å­˜å‰¯æœ¬
        
        # 3. é€ token ç”Ÿæˆï¼ˆDecodeï¼‰
        #    - æ¯æ­¥åªå‰å‘ä¼ æ’­ 1 ä¸ª token
        #    - åˆ©ç”¨ KV Cache é¿å…é‡å¤è®¡ç®—
        #    - æ”¯æŒæ‰¹é‡é‡‡æ ·ï¼ˆnum_samples > 1ï¼‰
        
        # 4. å·¥å…·è°ƒç”¨çŠ¶æ€æœº
        #    - æ£€æµ‹ <|python_start|> token
        #    - æ‰§è¡Œ Python è¡¨è¾¾å¼
        #    - å¼ºåˆ¶æ³¨å…¥ <|output_start|>ç»“æœ<|output_end|>
```

**å·¥å…·ä½¿ç”¨ï¼ˆCalculatorï¼‰**ï¼š

```python
def use_calculator(expr):
    # å®‰å…¨æ‰§è¡Œæ•°å­¦è¡¨è¾¾å¼æˆ–å­—ç¬¦ä¸²æ“ä½œ
    # æ”¯æŒï¼š
    #   - æ•°å­¦è¿ç®—ï¼š1 + 2 * 3
    #   - å­—ç¬¦ä¸²æ–¹æ³•ï¼š"strawberry".count("r")
    # 
    # å®‰å…¨æªæ–½ï¼š
    #   - 3 ç§’è¶…æ—¶
    #   - ç¦æ­¢å±é™©æ“ä½œï¼ˆimport, exec, __ç­‰ï¼‰
    #   - ç©ºå‘½åç©ºé—´
```

#### 3.1.3 åˆ†è¯å™¨ï¼ˆ`nanochat/tokenizer.py`ï¼‰

**åŒå®ç°æ¶æ„**ï¼š

1. **HuggingFaceTokenizer**ï¼š
   - ç”¨äºè®­ç»ƒå’Œæ¨ç†
   - çµæ´»ä½†ç¨æ…¢

2. **RustBPETokenizer**ï¼ˆæ¨èï¼‰ï¼š
   - è®­ç»ƒï¼šä½¿ç”¨ `rustbpe`ï¼ˆRust å®ç°ï¼‰
   - æ¨ç†ï¼šä½¿ç”¨ `tiktoken`ï¼ˆC++ å®ç°ï¼‰
   - æ€§èƒ½ä¼˜å¼‚

**è®­ç»ƒæµç¨‹**ï¼š

```python
# scripts/tok_train.py

# 1. ä¸‹è½½æ•°æ®
dataset.download_shards(n=8)  # ~2B å­—ç¬¦

# 2. è®­ç»ƒåˆ†è¯å™¨
tokenizer = RustBPETokenizer.train_from_iterator(
    text_iterator=text_stream,
    vocab_size=65536,
)

# 3. ä¿å­˜
tokenizer.save("tokenizer/")
# - tokenizer.pkl (tiktoken Encoding å¯¹è±¡)
# - token_bytes.pt (æ¯ä¸ª token çš„å­—èŠ‚é•¿åº¦)
```

**ç‰¹æ®Š Token**ï¼š

```python
SPECIAL_TOKENS = [
    "<|bos|>",              # æ–‡æ¡£å¼€å§‹
    "<|user_start|>",       # ç”¨æˆ·æ¶ˆæ¯å¼€å§‹
    "<|user_end|>",         # ç”¨æˆ·æ¶ˆæ¯ç»“æŸ
    "<|assistant_start|>",  # åŠ©æ‰‹æ¶ˆæ¯å¼€å§‹
    "<|assistant_end|>",    # åŠ©æ‰‹æ¶ˆæ¯ç»“æŸ
    "<|python_start|>",     # Python å·¥å…·è°ƒç”¨å¼€å§‹
    "<|python_end|>",       # Python å·¥å…·è°ƒç”¨ç»“æŸ
    "<|output_start|>",     # å·¥å…·è¾“å‡ºå¼€å§‹
    "<|output_end|>",       # å·¥å…·è¾“å‡ºç»“æŸ
]
```

**å¯¹è¯æ¸²æŸ“**ï¼š

```python
def render_conversation(conversation, max_tokens=2048):
    # è¾“å…¥ï¼š{"messages": [{"role": "user", "content": "..."}, ...]}
    # è¾“å‡ºï¼š
    #   - ids: List[int] - token åºåˆ—
    #   - mask: List[int] - ç›‘ç£æ©ç ï¼ˆ1=è®­ç»ƒï¼Œ0=ä¸è®­ç»ƒï¼‰
    
    # è§„åˆ™ï¼š
    # - ç”¨æˆ·æ¶ˆæ¯ï¼šmask=0ï¼ˆä¸è®­ç»ƒï¼‰
    # - åŠ©æ‰‹æ¶ˆæ¯ï¼šmask=1ï¼ˆè®­ç»ƒï¼‰
    # - å·¥å…·è¾“å‡ºï¼šmask=0ï¼ˆæµ‹è¯•æ—¶ç”± Python ç”Ÿæˆï¼‰
```

#### 3.1.4 æ•°æ®åŠ è½½å™¨ï¼ˆ`nanochat/dataloader.py`ï¼‰

**åˆ†å¸ƒå¼æµå¼åŠ è½½**ï¼š

```python
def tokenizing_distributed_data_loader(B, T, split, device):
    # B: batch sizeï¼ˆæ¯è®¾å¤‡ï¼‰
    # T: sequence length
    # split: "train" æˆ– "val"
    
    # æµç¨‹ï¼š
    # 1. ä» Parquet æ–‡ä»¶æµå¼è¯»å–æ–‡æ¡£
    #    - å„ rank è¯»å–ä¸åŒçš„åˆ†ç‰‡ï¼ˆrank, rank+world_size, ...ï¼‰
    #    
    # 2. æ‰¹é‡åˆ†è¯
    #    - tokenizer_batch_size=128
    #    - num_threads=4
    #    
    # 3. ç´¯ç§¯åˆ° deque ç¼“å†²åŒº
    #    - éœ€è¦ B*T+1 ä¸ª token æ‰ yield
    #    
    # 4. æ„é€  (inputs, targets)
    #    - inputs: tokens[:-1]
    #    - targets: tokens[1:]
    #    - å½¢çŠ¶ï¼š(B, T)
    
    # ç‰¹æ€§ï¼š
    # - æ— é™å¾ªç¯ï¼ˆæ— é™ epochï¼‰
    # - è‡ªåŠ¨å¤„ç†åˆ†å¸ƒå¼
    # - å†…å­˜é«˜æ•ˆï¼ˆæµå¼ï¼‰
```

### 3.2 è®­ç»ƒè„šæœ¬

#### 3.2.1 åŸºç¡€æ¨¡å‹è®­ç»ƒï¼ˆ`scripts/base_train.py`ï¼‰

**ä¸»è¦æµç¨‹**ï¼š

```python
# 1. é…ç½®è§£æ
#    - ä½¿ç”¨ configurator.py ä» CLI è¯»å–å‚æ•°
#    - æ”¯æŒé…ç½®æ–‡ä»¶è¦†ç›–

# 2. è®¡ç®—åˆå§‹åŒ–
#    - DDP è®¾ç½®ï¼ˆå¦‚æœå¤š GPUï¼‰
#    - è®¾å¤‡é€‰æ‹©ï¼ˆCUDA/MPS/CPUï¼‰
#    - éšæœºç§å­å›ºå®šï¼ˆreproducibilityï¼‰

# 3. æ¨¡å‹åˆ›å»º
#    - depth -> (n_layer, n_embd, n_head)
#    - åœ¨ meta device ä¸Šåˆå§‹åŒ–ï¼ˆèŠ‚çœå†…å­˜ï¼‰
#    - è½¬ç§»åˆ°è®¾å¤‡å¹¶åˆå§‹åŒ–æƒé‡

# 4. ä¼˜åŒ–å™¨é…ç½®
#    - Muon for Linear å±‚
#    - AdamW for Embedding + LM Head
#    - å­¦ä¹ ç‡æ ¹æ® d_model ç¼©æ”¾

# 5. æ•°æ®åŠ è½½å™¨
#    - Train: æ— é™æµ
#    - Val: æŒ‰éœ€æ„å»º

# 6. è®­ç»ƒå¾ªç¯
for step in range(num_iterations + 1):
    # è¯„ä¼°éªŒè¯æŸå¤±
    if step % eval_every == 0:
        val_bpb = evaluate_bpb(model, val_loader, ...)
    
    # è¯„ä¼° CORE æŒ‡æ ‡
    if step % core_metric_every == 0:
        core_score = evaluate_model(model, tokenizer, ...)
    
    # é‡‡æ ·å±•ç¤º
    if step % sample_every == 0:
        generate_samples(...)
    
    # è®­ç»ƒæ­¥éª¤
    for micro_step in range(grad_accum_steps):
        loss = model(x, y)
        loss.backward()
        x, y = next(train_loader)  # é¢„å–
    
    # æ¢¯åº¦è£å‰ª + ä¼˜åŒ–å™¨æ­¥è¿›
    clip_grad_norm_(model.parameters(), grad_clip)
    optimizer.step()
    
    # ä¿å­˜æ£€æŸ¥ç‚¹
    if last_step:
        save_checkpoint(...)

# 7. æŠ¥å‘Šç”Ÿæˆ
get_report().log(section="Base model training", data=...)
```

**å…³é”®è¶…å‚æ•°**ï¼š

```python
# æ¨¡å‹æ¶æ„
depth = 20                    # æ¨¡å‹æ·±åº¦
max_seq_len = 2048           # åºåˆ—é•¿åº¦

# è®­ç»ƒè§„æ¨¡
target_param_data_ratio = 20  # Chinchilla æ¯”ä¾‹
total_batch_size = 524288     # ~0.5M tokens/step
device_batch_size = 32        # æ¯è®¾å¤‡æ‰¹æ¬¡å¤§å°

# ä¼˜åŒ–å™¨
matrix_lr = 0.02             # Muon å­¦ä¹ ç‡
embedding_lr = 0.2           # åµŒå…¥å­¦ä¹ ç‡
unembedding_lr = 0.004       # LM Head å­¦ä¹ ç‡
grad_clip = 1.0              # æ¢¯åº¦è£å‰ª

# å­¦ä¹ ç‡è°ƒåº¦
warmup_ratio = 0.0           # é¢„çƒ­æ¯”ä¾‹
warmdown_ratio = 0.2         # è¡°å‡æ¯”ä¾‹
final_lr_frac = 0.0          # æœ€ç»ˆå­¦ä¹ ç‡æ¯”ä¾‹

# è¯„ä¼°é¢‘ç‡
eval_every = 250             # éªŒè¯è¯„ä¼°
core_metric_every = 2000     # CORE è¯„ä¼°
sample_every = 2000          # é‡‡æ ·å±•ç¤º
```

#### 3.2.2 ç›‘ç£å¾®è°ƒï¼ˆ`scripts/chat_sft.py`ï¼‰

**æ•°æ®æ··åˆ**ï¼š

```python
train_ds = TaskMixture([
    ARC(subset="ARC-Easy", split="train"),        # 2.3K ç§‘å­¦é—®ç­”
    ARC(subset="ARC-Challenge", split="train"),   # 1.1K æŒ‘æˆ˜é—®ç­”
    GSM8K(subset="main", split="train"),          # 8K æ•°å­¦é—®é¢˜
    SmolTalk(split="train", stop=10_000),         # 10K å¯¹è¯
    CustomJSON(filepath="identity_conversations.jsonl"),  # 1K èº«ä»½å¯¹è¯
    SimpleSpelling(size=300, split="train"),      # 300 æ‹¼å†™ä»»åŠ¡
    SpellingBee(size=300, split="train"),         # 300 å­—æ¯è®¡æ•°
])
# æ€»è®¡ï¼š~23K è®­ç»ƒæ ·æœ¬
```

**æ•°æ®å¤„ç†**ï¼š

```python
def sft_data_generator(dataset, batch_size):
    # 1. è¿­ä»£æ•°æ®é›†ï¼ˆåˆ†å¸ƒå¼ï¼šæ¯ä¸ª rank å¤„ç†ä¸åŒæ ·æœ¬ï¼‰
    for i in range(ddp_rank, len(dataset), ddp_world_size):
        doc = dataset[i]
        
        # 2. æ¸²æŸ“å¯¹è¯ä¸º token åºåˆ—
        ids, mask = tokenizer.render_conversation(doc)
        batch.append((ids, mask))
        
        # 3. æ‰¹æ¬¡å¯¹é½ï¼ˆpaddingï¼‰
        if len(batch) == batch_size:
            # - æ‰¾æœ€é•¿åºåˆ—
            # - ç”¨ <|assistant_end|> å¡«å……
            # - mask=0 çš„ä½ç½® target=-1ï¼ˆignore_indexï¼‰
            yield collate_and_yield(batch)
```

**è®­ç»ƒç‰¹ç‚¹**ï¼š

- **æºæ¨¡å‹**ï¼šå¯é€‰ `base` æˆ– `mid`ï¼ˆä¸­é—´è®­ç»ƒåçš„æ¨¡å‹ï¼‰
- **ä¼˜åŒ–å™¨**ï¼šåŒæ ·ä½¿ç”¨ Muon + AdamWï¼Œä½†å­¦ä¹ ç‡é™ä½ï¼ˆinit_lr_frac=0.02ï¼‰
- **å­¦ä¹ ç‡è°ƒåº¦**ï¼šçº¿æ€§è¡°å‡åˆ° 0
- **è¯„ä¼°**ï¼šéªŒè¯æŸå¤± + MMLU/ARC å‡†ç¡®ç‡
- **epoch æ•°**ï¼šé€šå¸¸ 1 epoch è¶³å¤Ÿ

#### 3.2.3 å¼ºåŒ–å­¦ä¹ ï¼ˆ`scripts/chat_rl.py`ï¼‰

**GRPO ç®—æ³•**ï¼ˆGroup Relative Policy Optimizationï¼‰ï¼š

```python
# 1. é‡‡æ ·é˜¶æ®µ
for problem in dataset:
    prompt_tokens = tokenizer.render_for_completion(problem)
    
    # ç”Ÿæˆå¤šä¸ªå€™é€‰ï¼ˆnum_samples=4ï¼‰
    completions, masks = engine.generate_batch(
        prompt_tokens,
        num_samples=4,
        temperature=1.0,
    )
    
    # è¯„ä¼°å¥–åŠ±
    for completion in completions:
        reward = task.evaluate(problem, completion)
        rewards.append(reward)

# 2. ä¼˜åŠ¿è®¡ç®—
mean_reward = mean(rewards)
advantages = [r - mean_reward for r in rewards]

# 3. ç­–ç•¥ä¼˜åŒ–
for completion, advantage in zip(completions, advantages):
    # è®¡ç®—å¯¹æ•°æ¦‚ç‡æ¯”
    log_probs_new = model.forward_log_probs(completion)
    log_probs_old = log_probs_new.detach()  # å‚è€ƒç­–ç•¥
    
    # GRPO æŸå¤±
    ratio = exp(log_probs_new - log_probs_old)
    loss = -advantage * ratio
    loss.backward()

optimizer.step()
```

**ç‰¹æ€§**ï¼š
- **æ— éœ€å¥–åŠ±æ¨¡å‹**ï¼šç›´æ¥ä½¿ç”¨ä»»åŠ¡è¯„ä¼°å‡½æ•°
- **ä¸»è¦ç”¨äº GSM8K**ï¼šæ•°å­¦é—®é¢˜æœ‰æ˜ç¡®çš„å¯¹é”™
- **On-policy**ï¼šæ¯æ‰¹æ¬¡é‡æ–°é‡‡æ ·
- **Group normalization**ï¼šä¼˜åŠ¿åœ¨ç»„å†…å½’ä¸€åŒ–

### 3.3 è¯„ä¼°ç³»ç»Ÿ

#### 3.3.1 CORE è¯„ä¼°ï¼ˆ`nanochat/core_eval.py`ï¼‰

**CORE æŒ‡æ ‡**ï¼ˆæ¥è‡ª DCLM è®ºæ–‡ï¼‰ï¼š

```python
# å®šä¹‰
CORE = centered_mean([
    ARC-Challenge,
    ARC-Easy,
    HellaSwag,
    MMLU,
    OpenBookQA,
    PIQA,
    Winogrande,
])

# centered_mean: å°†æ¯ä¸ªä»»åŠ¡åˆ†æ•°å±…ä¸­åˆ° [0, 1]ï¼Œç„¶åå¹³å‡
def centered_mean(scores):
    centered = [(s - random_baseline) / (1 - random_baseline) 
                for s in scores]
    return mean(centered)
```

**è¯„ä¼°æµç¨‹**ï¼š

```python
def evaluate_model(model, tokenizer, device, max_per_task=500):
    # 1. åŠ è½½æ‰€æœ‰ CORE ä»»åŠ¡
    tasks = {
        "ARC-Challenge": ARC("ARC-Challenge", "test"),
        "ARC-Easy": ARC("ARC-Easy", "test"),
        # ... å…¶ä»–ä»»åŠ¡
    }
    
    # 2. å¯¹æ¯ä¸ªä»»åŠ¡è¯„ä¼°
    for task_name, task in tasks.items():
        correct = 0
        total = min(max_per_task, len(task))
        
        for problem in task[:total]:
            # æ¸²æŸ“ä¸ºå¤šé€‰é¢˜
            prompt = render_mc(problem.question, letters, choices)
            
            # è®¡ç®—æ¯ä¸ªé€‰é¡¹çš„å›°æƒ‘åº¦
            perplexities = []
            for choice in choices:
                tokens = tokenizer.encode(prompt + choice)
                loss = model(tokens, targets)
                perplexities.append(exp(loss))
            
            # é€‰æ‹©å›°æƒ‘åº¦æœ€ä½çš„
            prediction = argmin(perplexities)
            if prediction == problem.answer:
                correct += 1
        
        accuracy = correct / total
        scores[task_name] = accuracy
    
    # 3. è®¡ç®— CORE åˆ†æ•°
    core_score = centered_mean(scores.values())
    return core_score, scores
```

#### 3.3.2 èŠå¤©è¯„ä¼°ï¼ˆ`scripts/chat_eval.py`ï¼‰

**æ”¯æŒçš„ä»»åŠ¡**ï¼š

1. **MMLU**ï¼šå¤šé¢†åŸŸé€‰æ‹©é¢˜ï¼ˆ57 ä¸ªå­é›†ï¼‰
2. **ARC-Easy/Challenge**ï¼šç§‘å­¦æ¨ç†
3. **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜
4. **HumanEval**ï¼šPython ä»£ç ç”Ÿæˆ
5. **ChatCORE**ï¼šå¯¹è¯ç‰ˆ CORE è¯„ä¼°

**è¯„ä¼°æ¨¡å¼**ï¼š

```python
# åˆ†ç±»ä»»åŠ¡ï¼ˆMultiple Choiceï¼‰
def evaluate_categorical(task, model, tokenizer, engine):
    for problem in task:
        # 1. æ¸²æŸ“æç¤º
        prompt = render_mc(problem.question, choices)
        tokens = tokenizer.encode(prompt)
        
        # 2. ç”Ÿæˆå›å¤
        completion = engine.generate_batch(tokens, temperature=0)
        answer = tokenizer.decode(completion)
        
        # 3. æå–å­—æ¯ç­”æ¡ˆ
        predicted_letter = extract_letter(answer)
        
        # 4. è¯„ä¼°
        correct = (predicted_letter == problem.answer)

# ç”Ÿæˆä»»åŠ¡ï¼ˆGenerativeï¼‰
def evaluate_generative(task, model, tokenizer, engine):
    for problem in task:
        # 1. æ¸²æŸ“æç¤º
        prompt = problem.question
        tokens = tokenizer.encode(prompt)
        
        # 2. ç”Ÿæˆå›å¤
        completion = engine.generate_batch(
            tokens,
            max_tokens=512,
            temperature=0,
        )
        answer = tokenizer.decode(completion)
        
        # 3. ä»»åŠ¡ç‰¹å®šè¯„ä¼°
        correct = task.evaluate(problem, answer)
        # ä¾‹å¦‚ï¼šGSM8K æå–æœ€ç»ˆæ•°å­—å¹¶æ¯”è¾ƒ
```

### 3.4 å·¥å…·å’Œè¾…åŠ©æ¨¡å—

#### 3.4.1 æ£€æŸ¥ç‚¹ç®¡ç†ï¼ˆ`nanochat/checkpoint_manager.py`ï¼‰

```python
def save_checkpoint(checkpoint_dir, step, model_state, optimizer_states, meta):
    # ä¿å­˜ï¼š
    # - model_state.pt: æ¨¡å‹æƒé‡
    # - optimizer_0.pt, optimizer_1.pt: ä¼˜åŒ–å™¨çŠ¶æ€
    # - meta.pt: å…ƒæ•°æ®ï¼ˆstep, é…ç½®ç­‰ï¼‰
    pass

def load_model(source, device, phase="eval", model_tag=None, step=None):
    # source: "base", "mid", "sft", "rl"
    # phase: "train" (åŠ è½½ä¼˜åŒ–å™¨) æˆ– "eval" (ä»…æ¨¡å‹)
    # 
    # è‡ªåŠ¨æŸ¥æ‰¾ï¼š
    # - base_checkpoints/{model_tag}/
    # - chatmid_checkpoints/{model_tag}/
    # - chatsft_checkpoints/{model_tag}/
    # - chatrl_checkpoints/{model_tag}/
    
    return model, tokenizer, meta
```

#### 3.4.2 é…ç½®å™¨ï¼ˆ`nanochat/configurator.py`ï¼‰

**ç®€æ˜“é…ç½®ç³»ç»Ÿ**ï¼š

```python
# ç”¨æ³• 1ï¼šå‘½ä»¤è¡Œå‚æ•°
python script.py --depth=20 --device_batch_size=16

# ç”¨æ³• 2ï¼šé…ç½®æ–‡ä»¶
# config/my_config.py
depth = 26
device_batch_size = 16

python script.py config/my_config.py

# ç”¨æ³• 3ï¼šæ··åˆ
python script.py config/my_config.py --depth=32

# å®ç°åŸç†ï¼š
# 1. æ‰«æ sys.argv
# 2. æ‰§è¡Œé…ç½®æ–‡ä»¶ï¼ˆexec(open(file).read())ï¼‰
# 3. è§£æ --key=value å¹¶æ›´æ–° globals()
```

#### 3.4.3 æŠ¥å‘Šç”Ÿæˆï¼ˆ`nanochat/report.py`ï¼‰

**æŠ¥å‘Šç³»ç»Ÿ**ï¼š

```python
# å„ä¸ªè„šæœ¬è°ƒç”¨
get_report().log(section="è®­ç»ƒé˜¶æ®µ", data={
    "å‚æ•°": "å€¼",
    "æŒ‡æ ‡": 0.123,
})

# æœ€ç»ˆç”Ÿæˆ
python -m nanochat.report generate
# è¾“å‡ºï¼šreport.mdï¼ˆåŒ…å«æ‰€æœ‰é˜¶æ®µçš„æ±‡æ€»ï¼‰
```

**æŠ¥å‘Šå†…å®¹**ï¼š
- ç³»ç»Ÿä¿¡æ¯ï¼ˆGPUã€å†…å­˜ã€ä»£ç ç»Ÿè®¡ï¼‰
- å„é˜¶æ®µé…ç½®å’Œç»“æœ
- è¯„ä¼°æŒ‡æ ‡è¡¨æ ¼
- è®­ç»ƒæ—¶é•¿å’Œæˆæœ¬ä¼°ç®—

---

## å››ã€è®­ç»ƒæµç¨‹è¯¦è§£

### 4.1 å®Œæ•´è®­ç»ƒæµç¨‹ï¼ˆspeedrun.shï¼‰

**æ­¥éª¤æ‹†è§£**ï¼š

```bash
# ============ ç¯å¢ƒå‡†å¤‡ ============
# 1. å®‰è£… uv åŒ…ç®¡ç†å™¨
curl -LsSf https://astral.sh/uv/install.sh | sh

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
uv venv
source .venv/bin/activate

# 3. å®‰è£…ä¾èµ–
uv sync --extra gpu  # æˆ– --extra cpu

# ============ åˆ†è¯å™¨ ============
# 4. å®‰è£… Rust
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
source "$HOME/.cargo/env"

# 5. ç¼–è¯‘ rustbpe
uv run maturin develop --release --manifest-path rustbpe/Cargo.toml

# 6. ä¸‹è½½æ•°æ®å¹¶è®­ç»ƒåˆ†è¯å™¨
python -m nanochat.dataset -n 8           # ä¸‹è½½ 8 ä¸ªåˆ†ç‰‡ï¼ˆ~2B å­—ç¬¦ï¼‰
python -m nanochat.dataset -n 240 &       # åå°ä¸‹è½½æ›´å¤šï¼ˆé¢„è®­ç»ƒéœ€è¦ï¼‰
python -m scripts.tok_train --max_chars=2000000000  # è®­ç»ƒ
python -m scripts.tok_eval                # è¯„ä¼°

# ============ é¢„è®­ç»ƒ ============
# 7. ç­‰å¾…æ•°æ®ä¸‹è½½å®Œæˆ
wait $DATASET_DOWNLOAD_PID

# 8. åŸºç¡€æ¨¡å‹è®­ç»ƒ
torchrun --standalone --nproc_per_node=8 -m scripts.base_train -- --depth=20

# 9. è¯„ä¼°åŸºç¡€æ¨¡å‹
torchrun --standalone --nproc_per_node=8 -m scripts.base_loss   # Bits per byte
torchrun --standalone --nproc_per_node=8 -m scripts.base_eval   # CORE score

# ============ ä¸­é—´è®­ç»ƒ ============
# 10. ä¸‹è½½èº«ä»½å¯¹è¯æ•°æ®
curl -L -o $NANOCHAT_BASE_DIR/identity_conversations.jsonl \
    https://karpathy-public.s3.us-west-2.amazonaws.com/identity_conversations.jsonl

# 11. Midtraining
torchrun --standalone --nproc_per_node=8 -m scripts.mid_train
torchrun --standalone --nproc_per_node=8 -m scripts.chat_eval -- -i mid

# ============ ç›‘ç£å¾®è°ƒ ============
# 12. SFT
torchrun --standalone --nproc_per_node=8 -m scripts.chat_sft
torchrun --standalone --nproc_per_node=8 -m scripts.chat_eval -- -i sft

# ============ æ¨ç† ============
# 13. å‘½ä»¤è¡ŒèŠå¤©
python -m scripts.chat_cli -p "Why is the sky blue?"

# 14. Web ç•Œé¢
python -m scripts.chat_web
# è®¿é—® http://localhost:8000

# ============ å¯é€‰ï¼šå¼ºåŒ–å­¦ä¹  ============
# 15. RLï¼ˆä»… GSM8Kï¼‰
# torchrun --standalone --nproc_per_node=8 -m scripts.chat_rl
# torchrun --standalone --nproc_per_node=8 -m scripts.chat_eval -- -i rl -a GSM8K

# ============ æŠ¥å‘Šç”Ÿæˆ ============
# 16. ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
python -m nanochat.report generate
# è¾“å‡ºï¼šreport.md
```

### 4.2 è®­ç»ƒæ—¶é—´å’Œæˆæœ¬

**d20 æ¨¡å‹ï¼ˆspeedrun.shï¼Œ561M å‚æ•°ï¼‰**ï¼š

```
è®¾å¤‡ï¼š8XH100 GPU
è®­ç»ƒæ—¶é•¿ï¼š~4 å°æ—¶
æˆæœ¬ï¼š~$100ï¼ˆ$24/å°æ—¶ Ã— 4 å°æ—¶ï¼‰

é˜¶æ®µåˆ†è§£ï¼š
- åˆ†è¯å™¨è®­ç»ƒï¼š10 åˆ†é’Ÿ
- æ•°æ®ä¸‹è½½ï¼š20 åˆ†é’Ÿï¼ˆåå°ï¼‰
- é¢„è®­ç»ƒï¼š2.5 å°æ—¶
- Midtrainingï¼š30 åˆ†é’Ÿ
- SFTï¼š30 åˆ†é’Ÿ
- è¯„ä¼°ï¼š30 åˆ†é’Ÿ

è®­ç»ƒ token æ•°ï¼š
- é¢„è®­ç»ƒï¼š~11B tokensï¼ˆ20Ã—å‚æ•°é‡ï¼ŒChinchillaï¼‰
- Midtrainingï¼š~500M tokens
- SFTï¼š~23K æ ·æœ¬ Ã— å¹³å‡é•¿åº¦

æ€§èƒ½ï¼š
- CORE scoreï¼š~0.22
- MFUï¼š~40%ï¼ˆH100 ç†è®ºæ€§èƒ½çš„ 40%ï¼‰
```

**d26 æ¨¡å‹ï¼ˆæ›´å¤§æ¨¡å‹ï¼‰**ï¼š

```
è®¾å¤‡ï¼š8XH100 GPU
è®­ç»ƒæ—¶é•¿ï¼š~12 å°æ—¶
æˆæœ¬ï¼š~$300

å‚æ•°é‡ï¼š~1.2B
è®­ç»ƒ token æ•°ï¼š~24B tokens

æ€§èƒ½ï¼š
- CORE scoreï¼š~0.26ï¼ˆè¶…è¶Š GPT-2ï¼‰
```

**d32 æ¨¡å‹ï¼ˆrun1000.shï¼Œ1.9B å‚æ•°ï¼‰**ï¼š

```
è®¾å¤‡ï¼š8XH100 GPU
è®­ç»ƒæ—¶é•¿ï¼š~33 å°æ—¶
æˆæœ¬ï¼š~$800

è®­ç»ƒ token æ•°ï¼š~38B tokens

æ€§èƒ½ï¼š
- CORE scoreï¼šæ›´é«˜ï¼ˆå…·ä½“çœ‹ nanochat.karpathy.aiï¼‰
```

### 4.3 è¶…å‚æ•°è°ƒä¼˜å»ºè®®

**æ¨¡å‹è§„æ¨¡ç¼©æ”¾**ï¼š

```python
# è§„åˆ™ï¼š
# - n_embd = depth Ã— 64ï¼ˆå¯è°ƒåˆ° 128ï¼‰
# - n_head = ceil(n_embd / 128)
# - head_dim = 128ï¼ˆå›ºå®šï¼‰

# ç¤ºä¾‹ï¼š
depth = 20 -> n_embd = 1280, n_head = 10, params = 561M
depth = 26 -> n_embd = 1664, n_head = 13, params = 1.2B
depth = 32 -> n_embd = 2048, n_head = 16, params = 1.9B
```

**è®­ç»ƒ token æ•°**ï¼š

```python
# Chinchilla æœ€ä¼˜ï¼štokens = 20 Ã— params
# å¯ç”¨èŒƒå›´ï¼š10-30 Ã— params

# è®¡ç®—æ‰€éœ€åˆ†ç‰‡æ•°ï¼š
tokens_needed = params * 20
chars_needed = tokens_needed * 4.8  # å‡è®¾ 4.8 chars/token
shards_needed = chars_needed / 250e6  # æ¯åˆ†ç‰‡ 250M å­—ç¬¦
```

**æ‰¹æ¬¡å¤§å°**ï¼š

```python
# æ€»æ‰¹æ¬¡å¤§å°ï¼ˆæ¨èï¼‰ï¼š
# - å°æ¨¡å‹ï¼ˆ<1Bï¼‰ï¼š524,288 tokens
# - å¤§æ¨¡å‹ï¼ˆ1-3Bï¼‰ï¼š1,048,576 tokens

# è®¾å¤‡æ‰¹æ¬¡å¤§å°ï¼ˆæ ¹æ® VRAM è°ƒæ•´ï¼‰ï¼š
# - 80GB GPUï¼š32ï¼ˆdepth=20ï¼‰-> 16ï¼ˆdepth=26ï¼‰-> 8ï¼ˆdepth=32ï¼‰
# - 40GB GPUï¼šå‡åŠ
# - å• GPUï¼šå°½å¯èƒ½å¤§ï¼Œä»£ç ä¼šè‡ªåŠ¨ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
```

**å­¦ä¹ ç‡**ï¼š

```python
# åŸºæœ¬ä¸éœ€è¦è°ƒæ•´ï¼Œä»£ç ä¼šæ ¹æ® d_model è‡ªåŠ¨ç¼©æ”¾
# ä½†å¦‚æœå¿…é¡»è°ƒæ•´ï¼š
# - å¢å¤§æ¨¡å‹ -> è‡ªåŠ¨é™ä½ LRï¼ˆâˆ1/âˆšd_modelï¼‰
# - å¢å¤§æ‰¹æ¬¡ -> å¯çº¿æ€§å¢å¤§ LRï¼ˆä½†ä»£ç å·²ä¼˜åŒ–ï¼‰
```

### 4.4 å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

#### é—®é¢˜ 1ï¼šOOMï¼ˆæ˜¾å­˜ä¸è¶³ï¼‰

```bash
# è§£å†³æ–¹æ¡ˆï¼š
# 1. å‡å° device_batch_size
torchrun ... --device_batch_size=16  # ä» 32 å‡åŠ

# 2. å‡å°åºåˆ—é•¿åº¦
torchrun ... --max_seq_len=1024  # ä» 2048 å‡åŠ

# 3. å‡å°æ¨¡å‹è§„æ¨¡
torchrun ... --depth=16  # ä» 20 å‡å°

# 4. å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆéœ€è¦ä¿®æ”¹ä»£ç ï¼‰
```

#### é—®é¢˜ 2ï¼šè®­ç»ƒé€Ÿåº¦æ…¢

```bash
# æ£€æŸ¥ï¼š
# 1. MFUï¼ˆModel FLOPs Utilizationï¼‰
#    - ç›®æ ‡ï¼š>30%ï¼ˆH100ï¼‰
#    - å¦‚æœä½ï¼šå¯èƒ½æ˜¯æ•°æ®åŠ è½½ç“¶é¢ˆ

# 2. æ•°æ®åŠ è½½ä¼˜åŒ–
#    - å¢åŠ  tokenizer_threadsï¼ˆé»˜è®¤ 4ï¼‰
#    - å¢åŠ  tokenizer_batch_sizeï¼ˆé»˜è®¤ 128ï¼‰

# 3. ç¼–è¯‘ä¼˜åŒ–
#    - ç¡®ä¿ä½¿ç”¨ torch.compile
#    - å¯å°è¯• dynamic=True/False
```

#### é—®é¢˜ 3ï¼šåˆ†è¯å™¨å‹ç¼©ç‡ä½

```bash
# åŸå› ï¼š
# - è®­ç»ƒæ•°æ®å¤ªå°‘
# - vocab_size å¤ªå°

# è§£å†³ï¼š
# 1. å¢åŠ è®­ç»ƒæ•°æ®
python -m nanochat.dataset -n 16  # ä» 8 å¢åŠ åˆ° 16

# 2. å¢åŠ  vocab_sizeï¼ˆéœ€è¦é‡æ–°è®­ç»ƒï¼‰
python -m scripts.tok_train --vocab_size=100000
```

#### é—®é¢˜ 4ï¼šè¯„ä¼°æŒ‡æ ‡ä¸æå‡

```bash
# è°ƒè¯•æ­¥éª¤ï¼š
# 1. æ£€æŸ¥è®­ç»ƒæŸå¤±æ˜¯å¦ä¸‹é™
#    - å¦‚æœä¸ä¸‹é™ï¼šå­¦ä¹ ç‡æˆ–ä¼˜åŒ–å™¨é—®é¢˜

# 2. æ£€æŸ¥éªŒè¯æŸå¤±
#    - å¦‚æœä¸‹é™ä½†æŒ‡æ ‡ä¸å‡ï¼šå¯èƒ½æ˜¯è¯„ä¼°ä»£ç é—®é¢˜

# 3. æ£€æŸ¥æ ·æœ¬è¾“å‡º
#    - ä½¿ç”¨ sample_every æŸ¥çœ‹ç”Ÿæˆè´¨é‡

# 4. å¢åŠ è®­ç»ƒæ—¶é•¿
#    - å°æ¨¡å‹éœ€è¦æ›´å¤šæ•°æ®æ‰èƒ½å­¦ä¼šä»»åŠ¡
```

---

## äº”ã€ä½¿ç”¨æŒ‡å—

### 5.1 å¿«é€Ÿå¼€å§‹

#### 5.1.1 ç¯å¢ƒæ­å»º

```bash
# 1. å…‹éš†ä»“åº“
git clone https://github.com/karpathy/nanochat.git
cd nanochat

# 2. å®‰è£… uvï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
curl -LsSf https://astral.sh/uv/install.sh | sh

# 3. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
uv venv

# 4. æ¿€æ´»ç¯å¢ƒ
source .venv/bin/activate  # Linux/Mac
# æˆ–
.venv\Scripts\activate     # Windows

# 5. å®‰è£…ä¾èµ–
uv sync --extra gpu        # GPU ç‰ˆæœ¬
# æˆ–
uv sync --extra cpu        # CPU ç‰ˆæœ¬
```

#### 5.1.2 è¿è¡Œ speedrunï¼ˆæ¨èï¼‰

```bash
# åœ¨ 8XH100 èŠ‚ç‚¹ä¸Šï¼š
bash speedrun.sh

# æˆ–åœ¨ screen ä¼šè¯ä¸­ï¼š
screen -L -Logfile speedrun.log -S speedrun bash speedrun.sh

# ç›‘æ§è¿›åº¦ï¼ˆå¦ä¸€ä¸ªç»ˆç«¯ï¼‰ï¼š
tail -f speedrun.log

# åˆ†ç¦» screenï¼šCtrl-A D
# é‡æ–°è¿æ¥ï¼šscreen -r speedrun
```

#### 5.1.3 ä»…æ¨ç†ï¼ˆä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼‰

```bash
# 1. ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå‡è®¾å¯ç”¨ï¼‰
# wget https://... -O ~/.cache/nanochat/base_checkpoints/d20/

# 2. ä¸‹è½½åˆ†è¯å™¨
# wget https://... -O ~/.cache/nanochat/tokenizer/

# 3. å‘½ä»¤è¡ŒèŠå¤©
python -m scripts.chat_cli -p "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹è‡ªå·±"

# 4. Web ç•Œé¢
python -m scripts.chat_web
# è®¿é—® http://localhost:8000
```

### 5.2 è‡ªå®šä¹‰è®­ç»ƒ

#### 5.2.1 è®­ç»ƒæ›´å°çš„æ¨¡å‹ï¼ˆCPU/MPSï¼‰

```bash
# å‚è€ƒ dev/runcpu.sh
python -m scripts.base_train \
    --depth=4 \
    --max_seq_len=512 \
    --device_batch_size=1 \
    --total_batch_size=512 \
    --num_iterations=20 \
    --eval_tokens=512 \
    --core_metric_every=-1
```

#### 5.2.2 è‡ªå®šä¹‰æ•°æ®é›†

**æ·»åŠ è‡ªå®šä¹‰ä»»åŠ¡**ï¼š

```python
# tasks/my_task.py

from tasks.common import Task

class MyTask(Task):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        # åŠ è½½ä½ çš„æ•°æ®
        self.data = load_my_data()
    
    @property
    def eval_type(self):
        return "categorical"  # æˆ– "generative"
    
    def num_examples(self):
        return len(self.data)
    
    def get_example(self, index):
        # è¿”å›å¯¹è¯æ ¼å¼ï¼š
        # {
        #     "messages": [
        #         {"role": "user", "content": "é—®é¢˜"},
        #         {"role": "assistant", "content": "ç­”æ¡ˆ"},
        #     ]
        # }
        item = self.data[index]
        return {
            "messages": [
                {"role": "user", "content": item["question"]},
                {"role": "assistant", "content": item["answer"]},
            ]
        }
    
    def evaluate(self, problem, completion):
        # ç”Ÿæˆä»»åŠ¡çš„è¯„ä¼°é€»è¾‘
        return completion.strip() == problem["answer"].strip()
```

**åœ¨ SFT ä¸­ä½¿ç”¨**ï¼š

```python
# scripts/chat_sft.pyï¼ˆä¿®æ”¹ï¼‰

from tasks.my_task import MyTask

train_ds = TaskMixture([
    ARC(...),
    MyTask(split="train"),  # æ·»åŠ ä½ çš„ä»»åŠ¡
    # ...
])
```

#### 5.2.3 è‡ªå®šä¹‰èº«ä»½/ä¸ªæ€§

```python
# 1. åˆ›å»ºèº«ä»½å¯¹è¯æ•°æ®
# dev/gen_synthetic_data.pyï¼ˆå‚è€ƒï¼‰

conversations = [
    {
        "messages": [
            {"role": "user", "content": "ä½ æ˜¯è°ï¼Ÿ"},
            {"role": "assistant", "content": "æˆ‘æ˜¯ MyBotï¼Œä¸€ä¸ªä¸“æ³¨äºæ•°å­¦è¾…å¯¼çš„ AI åŠ©æ‰‹ã€‚"},
        ]
    },
    # ... æ›´å¤šå¯¹è¯
]

# ä¿å­˜ä¸º JSONL
import json
with open("my_identity.jsonl", "w") as f:
    for conv in conversations:
        f.write(json.dumps(conv, ensure_ascii=False) + "\n")

# 2. åœ¨è®­ç»ƒä¸­ä½¿ç”¨
# scripts/chat_sft.pyï¼ˆä¿®æ”¹ï¼‰
identity_conversations_filepath = "my_identity.jsonl"
train_ds = TaskMixture([
    # ...
    CustomJSON(filepath=identity_conversations_filepath),
])
```

### 5.3 è¯„ä¼°å’Œè°ƒè¯•

#### 5.3.1 å•ç‹¬è¯„ä¼°æ¨¡å‹

```bash
# åŸºç¡€æ¨¡å‹ CORE è¯„ä¼°
torchrun --standalone --nproc_per_node=8 -m scripts.base_eval

# èŠå¤©æ¨¡å‹è¯„ä¼°ï¼ˆæ‰€æœ‰ä»»åŠ¡ï¼‰
torchrun --standalone --nproc_per_node=8 -m scripts.chat_eval -- -i sft

# èŠå¤©æ¨¡å‹è¯„ä¼°ï¼ˆç‰¹å®šä»»åŠ¡ï¼‰
torchrun --standalone --nproc_per_node=8 -m scripts.chat_eval -- -i sft -a GSM8K

# å• GPU è¯„ä¼°
python -m scripts.chat_eval -i sft -a MMLU
```

#### 5.3.2 è°ƒè¯•åˆ†è¯å™¨

```python
# 1. æ£€æŸ¥åˆ†è¯æ•ˆæœ
from nanochat.tokenizer import get_tokenizer

tokenizer = get_tokenizer()

text = "Hello, world! ä½ å¥½ä¸–ç•Œ"
tokens = tokenizer.encode(text)
print(f"Tokens: {tokens}")
print(f"Decoded: {tokenizer.decode(tokens)}")

# 2. å¯è§†åŒ–å¯¹è¯æ¸²æŸ“
conversation = {
    "messages": [
        {"role": "user", "content": "æµ‹è¯•"},
        {"role": "assistant", "content": "å¥½çš„"},
    ]
}

ids, mask = tokenizer.render_conversation(conversation)
print(tokenizer.visualize_tokenization(ids, mask))
# çº¢è‰²=ä¸è®­ç»ƒï¼Œç»¿è‰²=è®­ç»ƒ
```

#### 5.3.3 è°ƒè¯•æ¨¡å‹ç”Ÿæˆ

```python
# scripts/debug_generate.pyï¼ˆè‡ªå·±åˆ›å»ºï¼‰

from nanochat.checkpoint_manager import load_model
from nanochat.common import compute_init
from nanochat.engine import Engine

# åˆå§‹åŒ–
_, _, _, _, device = compute_init()
model, tokenizer, _ = load_model("sft", device)

# åˆ›å»ºå¼•æ“
engine = Engine(model, tokenizer)

# ç”Ÿæˆ
prompt = "ä¸ºä»€ä¹ˆå¤©ç©ºæ˜¯è“è‰²çš„ï¼Ÿ"
tokens = tokenizer.encode(prompt, prepend="<|bos|>")
tokens.append(tokenizer.encode_special("<|user_start|>"))
tokens.extend(tokenizer.encode(prompt))
tokens.append(tokenizer.encode_special("<|user_end|>"))
tokens.append(tokenizer.encode_special("<|assistant_start|>"))

print("Prompt:", tokenizer.decode(tokens))
print("\nGenerating...")

for token_column, token_masks in engine.generate(tokens, num_samples=1, max_tokens=100, temperature=0.7):
    token = token_column[0]
    chunk = tokenizer.decode([token])
    print(chunk, end="", flush=True)

print()
```

### 5.4 éƒ¨ç½²

#### 5.4.1 Web æœåŠ¡éƒ¨ç½²

```bash
# 1. æœ¬åœ°å¼€å‘
python -m scripts.chat_web
# é»˜è®¤ï¼šhttp://localhost:8000

# 2. æŒ‡å®šç«¯å£
python -m scripts.chat_web --port 8080

# 3. å…è®¸å¤–éƒ¨è®¿é—®
python -m scripts.chat_web --host 0.0.0.0 --port 8000

# 4. ç”Ÿäº§ç¯å¢ƒï¼ˆä½¿ç”¨ gunicornï¼‰
pip install gunicorn
gunicorn -w 4 -k uvicorn.workers.UvicornWorker scripts.chat_web:app
```

#### 5.4.2 CLI å·¥å…·

```bash
# äº¤äº’å¼èŠå¤©
python -m scripts.chat_cli

# å•æ¬¡é—®ç­”
python -m scripts.chat_cli -p "é—®é¢˜"

# æŒ‡å®šæ¨¡å‹
python -m scripts.chat_cli -i mid  # ä½¿ç”¨ midtrain æ¨¡å‹
python -m scripts.chat_cli -i sft  # ä½¿ç”¨ SFT æ¨¡å‹ï¼ˆé»˜è®¤ï¼‰
```

#### 5.4.3 API é›†æˆ

```python
# your_app.py

from nanochat.checkpoint_manager import load_model
from nanochat.engine import Engine
from nanochat.common import compute_init

class NanoChatAPI:
    def __init__(self):
        _, _, _, _, device = compute_init()
        model, tokenizer, _ = load_model("sft", device)
        self.engine = Engine(model, tokenizer)
        self.tokenizer = tokenizer
    
    def chat(self, message, history=None):
        """
        message: str - ç”¨æˆ·æ¶ˆæ¯
        history: List[Dict] - å†å²å¯¹è¯ï¼ˆå¯é€‰ï¼‰
        
        è¿”å›ï¼šstr - åŠ©æ‰‹å›å¤
        """
        # æ„é€ å¯¹è¯
        messages = history or []
        messages.append({"role": "user", "content": message})
        
        # æ¸²æŸ“ä¸º token
        conversation = {"messages": messages}
        tokens = self.tokenizer.render_for_completion(conversation)
        
        # ç”Ÿæˆ
        completion_tokens, _ = self.engine.generate_batch(
            tokens,
            num_samples=1,
            max_tokens=512,
            temperature=0.7,
        )
        
        # è§£ç 
        reply = self.tokenizer.decode(completion_tokens[0])
        
        # å»é™¤ç‰¹æ®Š token
        reply = reply.replace("<|assistant_end|>", "").strip()
        
        return reply

# ä½¿ç”¨
api = NanoChatAPI()
response = api.chat("ä½ å¥½")
print(response)
```

---

## å…­ã€æ€»ç»“ä¸æœ€ä½³å®è·µ

### 6.1 é¡¹ç›®æ ¸å¿ƒä»·å€¼

**nanochat çš„ç‹¬ç‰¹ä¹‹å¤„**ï¼š

1. **æ•™å­¦å‹å¥½**ï¼š
   - ä»£ç é‡é€‚ä¸­ï¼ˆ~8K è¡Œï¼‰
   - æ³¨é‡Šè¯¦å°½ï¼Œé€»è¾‘æ¸…æ™°
   - é¿å…è¿‡åº¦æŠ½è±¡å’Œé…ç½®å¤æ‚æ€§

2. **ç«¯åˆ°ç«¯å®Œæ•´**ï¼š
   - ä»æ•°æ®ä¸‹è½½åˆ° Web æœåŠ¡çš„å®Œæ•´æµç¨‹
   - æ¯ä¸ªé˜¶æ®µéƒ½æœ‰ç‹¬ç«‹è„šæœ¬ï¼Œå¯å•ç‹¬è¿è¡Œ
   - è‡ªåŠ¨åŒ–ç¨‹åº¦é«˜ï¼ˆspeedrun.sh ä¸€é”®è®­ç»ƒï¼‰

3. **æˆæœ¬å¯æ§**ï¼š
   - $100 å¿«é€ŸéªŒè¯
   - $300-$1000 è¾¾åˆ°å®ç”¨æ°´å¹³
   - å¯¹å­¦ä¹ è€…å’Œå°å›¢é˜Ÿå‹å¥½

4. **ç°ä»£æŠ€æœ¯**ï¼š
   - RoPEã€QK Normã€MQA/GQA
   - Muon ä¼˜åŒ–å™¨ï¼ˆäºŒé˜¶æ–¹æ³•ï¼‰
   - KV Cacheã€Flash Attention
   - å·¥å…·è°ƒç”¨èƒ½åŠ›

### 6.2 æœ€ä½³å®è·µ

#### 6.2.1 å¼€å‘æµç¨‹

```
1. å°è§„æ¨¡éªŒè¯
   â”œâ”€â†’ åœ¨ CPU/å• GPU ä¸Šè®­ç»ƒå°æ¨¡å‹ï¼ˆdepth=4ï¼‰
   â”œâ”€â†’ éªŒè¯ä»£ç é€»è¾‘æ­£ç¡®
   â””â”€â†’ å¿«é€Ÿè¿­ä»£ï¼ˆå‡ åˆ†é’Ÿåˆ°å‡ å°æ—¶ï¼‰

2. ä¸­ç­‰è§„æ¨¡å®éªŒ
   â”œâ”€â†’ ä½¿ç”¨å• GPU è®­ç»ƒ d12-d16 æ¨¡å‹
   â”œâ”€â†’ è°ƒæ•´è¶…å‚æ•°
   â””â”€â†’ è¯„ä¼°æ•ˆæœï¼ˆå‡ å°æ—¶åˆ°ä¸€å¤©ï¼‰

3. å…¨è§„æ¨¡è®­ç»ƒ
   â”œâ”€â†’ ä½¿ç”¨ 8XH100 è®­ç»ƒ d20-d32 æ¨¡å‹
   â”œâ”€â†’ è¿è¡Œå®Œæ•´æµç¨‹ï¼ˆspeedrun.shï¼‰
   â””â”€â†’ ç”ŸæˆæŠ¥å‘Šå’Œéƒ¨ç½²ï¼ˆå‡ å°æ—¶åˆ°å‡ å¤©ï¼‰
```

#### 6.2.2 ä»£ç ä¿®æ”¹å»ºè®®

**ä¿®æ”¹å‰å¿…è¯»**ï¼š

1. **å¼•ç”¨æ£€æŸ¥**ï¼š
   ```bash
   # ä½¿ç”¨ IDE çš„"æŸ¥æ‰¾å¼•ç”¨"åŠŸèƒ½
   # æˆ–ä½¿ç”¨ grep
   grep -r "function_name" nanochat/ scripts/
   ```

2. **ä¿æŒå®Œæ•´æ€§**ï¼š
   - ä¿®æ”¹å‡½æ•°æ—¶ï¼Œæä¾›å®Œæ•´ä»£ç 
   - ä¸è¦åªç»™ç‰‡æ®µï¼ˆé™¤éä»£ç å®¡æŸ¥ï¼‰

3. **åŒæ­¥ä¿®æ”¹**ï¼š
   - å¦‚æœä¿®æ”¹äº†å‡½æ•°ç­¾åï¼Œæ›´æ–°æ‰€æœ‰è°ƒç”¨ç‚¹
   - å¦‚æœä¿®æ”¹äº†é…ç½®ï¼Œæ›´æ–°é»˜è®¤å€¼å’Œæ–‡æ¡£

4. **æµ‹è¯•**ï¼š
   ```bash
   # è¿è¡Œæµ‹è¯•
   pytest tests/test_rustbpe.py -v
   
   # å°è§„æ¨¡éªŒè¯
   python -m scripts.base_train --depth=4 --num_iterations=10
   ```

#### 6.2.3 æ€§èƒ½ä¼˜åŒ–å»ºè®®

**è®­ç»ƒé€Ÿåº¦**ï¼š

1. **æ•°æ®åŠ è½½**ï¼š
   - å¢åŠ  `tokenizer_threads`ï¼ˆ4 -> 8ï¼‰
   - å¢åŠ  `tokenizer_batch_size`ï¼ˆ128 -> 256ï¼‰
   - ç¡®ä¿æ•°æ®å·²é¢„ä¸‹è½½

2. **è®¡ç®—æ•ˆç‡**ï¼š
   - ä½¿ç”¨ `torch.compile`ï¼ˆå·²å¯ç”¨ï¼‰
   - ä½¿ç”¨ bfloat16ï¼ˆå·²å¯ç”¨ï¼‰
   - å¯ç”¨ TF32ï¼ˆå·²å¯ç”¨ï¼‰
   - ç›®æ ‡ MFU > 30%

3. **å†…å­˜ä¼˜åŒ–**ï¼š
   - é™ä½ `device_batch_size`ï¼Œå¢åŠ  `grad_accum_steps`
   - ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆéœ€è¦æ·»åŠ ï¼‰
   - æ¸…ç†ä¸éœ€è¦çš„ä¸­é—´ç»“æœ

**æ¨ç†é€Ÿåº¦**ï¼š

1. **KV Cache**ï¼š
   - å·²å¯ç”¨ï¼ˆ`Engine` ç±»ï¼‰
   - ç¡®ä¿ä½¿ç”¨ `Engine.generate` è€Œé `model.generate`

2. **æ‰¹é‡æ¨ç†**ï¼š
   ```python
   # åˆ©ç”¨ num_samples å‚æ•°
   completions = engine.generate_batch(
       tokens,
       num_samples=8,  # å¹¶è¡Œç”Ÿæˆ 8 ä¸ªæ ·æœ¬
       ...
   )
   ```

3. **é‡åŒ–ï¼ˆæœªå®ç°ï¼Œå¯æ·»åŠ ï¼‰**ï¼š
   - int8 é‡åŒ–
   - int4 é‡åŒ–
   - éœ€è¦ä¿®æ”¹æ¨¡å‹ä»£ç 

### 6.3 æ‰©å±•æ–¹å‘

**å¯èƒ½çš„æ”¹è¿›**ï¼š

1. **æ¨¡å‹æ¶æ„**ï¼š
   - æ·»åŠ  MoEï¼ˆMixture of Expertsï¼‰
   - å°è¯•å…¶ä»–æ¿€æ´»å‡½æ•°ï¼ˆSwiGLUï¼‰
   - å®éªŒä¸åŒçš„å½’ä¸€åŒ–æ–¹æ³•

2. **è®­ç»ƒæ–¹æ³•**ï¼š
   - æ·»åŠ æ›´å¤š RL ç®—æ³•ï¼ˆPPOã€DPOï¼‰
   - å®ç°è¯¾ç¨‹å­¦ä¹ 
   - å¤šé˜¶æ®µå­¦ä¹ ç‡è°ƒæ•´

3. **æ•°æ®è´¨é‡**ï¼š
   - æ•°æ®å»é‡
   - æ•°æ®è¿‡æ»¤ï¼ˆæ¯’æ€§ã€è´¨é‡ï¼‰
   - æ›´å¤šåˆæˆæ•°æ®

4. **æ¨ç†ä¼˜åŒ–**ï¼š
   - æ¨¡å‹é‡åŒ–
   - æŠ•æœºè§£ç ï¼ˆSpeculative Decodingï¼‰
   - æ‰¹é‡åŠ¨æ€è°ƒåº¦

5. **å·¥å…·èƒ½åŠ›**ï¼š
   - æ·»åŠ æ›´å¤šå·¥å…·ï¼ˆæœç´¢ã€æ–‡ä»¶æ“ä½œï¼‰
   - å¤šè½®å·¥å…·è°ƒç”¨
   - è§†è§‰è¾“å…¥ï¼ˆå¤šæ¨¡æ€ï¼‰

### 6.4 å­¦ä¹ è·¯å¾„

**å¯¹äºåˆå­¦è€…**ï¼š

```
ç¬¬ 1 å‘¨ï¼šç†è§£åŸºç¡€
â”œâ”€â†’ é˜…è¯» README.md
â”œâ”€â†’ è¿è¡Œ speedrun.shï¼ˆå¦‚æœæœ‰ GPUï¼‰
â”‚   æˆ– dev/runcpu.shï¼ˆå¦‚æœæ²¡æœ‰ GPUï¼‰
â””â”€â†’ æŸ¥çœ‹ç”Ÿæˆçš„ report.md

ç¬¬ 2 å‘¨ï¼šç†è§£ä»£ç 
â”œâ”€â†’ é˜…è¯» nanochat/gpt.pyï¼ˆæ¨¡å‹å®šä¹‰ï¼‰
â”œâ”€â†’ é˜…è¯» nanochat/engine.pyï¼ˆæ¨ç†å¼•æ“ï¼‰
â””â”€â†’ é˜…è¯» scripts/base_train.pyï¼ˆè®­ç»ƒå¾ªç¯ï¼‰

ç¬¬ 3 å‘¨ï¼šä¿®æ”¹å®éªŒ
â”œâ”€â†’ ä¿®æ”¹æ¨¡å‹è¶…å‚æ•°ï¼ˆdepth, n_headï¼‰
â”œâ”€â†’ æ·»åŠ è‡ªå®šä¹‰æ•°æ®é›†
â””â”€â†’ è°ƒæ•´è®­ç»ƒé…ç½®

ç¬¬ 4 å‘¨ï¼šæ·±å…¥ä¼˜åŒ–
â”œâ”€â†’ ç ”ç©¶ä¼˜åŒ–å™¨ï¼ˆMuon vs AdamWï¼‰
â”œâ”€â†’ åˆ†ææ€§èƒ½ï¼ˆMFU, å†…å­˜ä½¿ç”¨ï¼‰
â””â”€â†’ å®éªŒæ–°æƒ³æ³•
```

**å¯¹äºè¿›é˜¶ç”¨æˆ·**ï¼š

```
ç ”ç©¶æ–¹å‘ 1ï¼šæ¶æ„åˆ›æ–°
â”œâ”€â†’ å®ç°æ–°çš„æ³¨æ„åŠ›æœºåˆ¶
â”œâ”€â†’ å®éªŒæ¨¡å‹å‹ç¼©æŠ€æœ¯
â””â”€â†’ å¯¹æ¯”ä¸åŒè®¾è®¡é€‰æ‹©

ç ”ç©¶æ–¹å‘ 2ï¼šè®­ç»ƒä¼˜åŒ–
â”œâ”€â†’ å®ç°æ–°çš„ä¼˜åŒ–ç®—æ³•
â”œâ”€â†’ ç ”ç©¶å­¦ä¹ ç‡è°ƒåº¦
â””â”€â†’ æ•°æ®æ··åˆç­–ç•¥

ç ”ç©¶æ–¹å‘ 3ï¼šåº”ç”¨æ‰©å±•
â”œâ”€â†’ å¤šæ¨¡æ€æ‰©å±•ï¼ˆè§†è§‰ï¼‰
â”œâ”€â†’ é•¿æ–‡æœ¬æ”¯æŒï¼ˆ>2048 tokensï¼‰
â””â”€â†’ ç‰¹å®šé¢†åŸŸé€‚åº”
```

### 6.5 å¸¸è§é™·é˜±

**é¿å…è¿™äº›é”™è¯¯**ï¼š

1. **è¿‡æ—©ä¼˜åŒ–**ï¼š
   - âŒ å…ˆè°ƒæ•´ä¼˜åŒ–å™¨å‚æ•°
   - âœ… å…ˆç¡®ä¿åŸºæœ¬æµç¨‹è·‘é€š

2. **å¿½è§†æ•°æ®è´¨é‡**ï¼š
   - âŒ åªå…³æ³¨æ¨¡å‹å¤§å°
   - âœ… æ•°æ®è´¨é‡ > æ¨¡å‹å¤§å°

3. **è¯„ä¼°ä¸å……åˆ†**ï¼š
   - âŒ åªçœ‹è®­ç»ƒæŸå¤±
   - âœ… å¤šæ ·åŒ–è¯„ä¼°ï¼ˆCORE, äººå·¥æ£€æŸ¥ï¼‰

4. **ä¾èµ–è¿‡å¤š**ï¼š
   - âŒ æ·»åŠ å¤§é‡å¤–éƒ¨åº“
   - âœ… ä¿æŒä»£ç ç®€æ´

5. **ç¼ºä¹æ–‡æ¡£**ï¼š
   - âŒ ä¿®æ”¹ä»£ç ä¸ç•™æ³¨é‡Š
   - âœ… è¯¦ç»†è®°å½•ä¿®æ”¹åŸå› 

### 6.6 ç»“è¯­

**nanochat çš„è®¾è®¡å“²å­¦**ï¼š

> "Simplicity is the ultimate sophistication."  
> â€”â€” Leonardo da Vinci

nanochat çš„ç›®æ ‡ä¸æ˜¯æˆä¸ºæœ€å¼ºå¤§æˆ–æœ€çµæ´»çš„ LLM æ¡†æ¶ï¼Œè€Œæ˜¯æˆä¸º**æœ€æ˜“ç†è§£å’Œä¿®æ”¹çš„å®Œæ•´ LLM å®ç°**ã€‚é€šè¿‡ç‰ºç‰²ä¸€äº›çµæ´»æ€§å’ŒæŠ½è±¡æ€§ï¼Œæˆ‘ä»¬è·å¾—äº†ï¼š

- **å¯è¯»æ€§**ï¼šä»»ä½•æœ‰ PyTorch ç»éªŒçš„äººéƒ½èƒ½è¯»æ‡‚
- **å¯ä¿®æ”¹æ€§**ï¼šæƒ³æ”¹ä»€ä¹ˆå°±æ”¹ä»€ä¹ˆï¼Œä¸éœ€è¦ç†è§£å¤æ‚çš„æŠ½è±¡å±‚
- **å¯å¤ç°æ€§**ï¼šå•ä¸ªè„šæœ¬ï¼Œç«¯åˆ°ç«¯ï¼Œç»“æœå¯å¤ç°
- **æ•™å­¦ä»·å€¼**ï¼šä½œä¸ºå­¦ä¹ ææ–™ï¼Œæ¯”å¤æ‚æ¡†æ¶æ›´æœ‰ä»·å€¼

**æœ€åå»ºè®®**ï¼š

1. **åŠ¨æ‰‹å®è·µ**ï¼šä¸è¦åªè¯»ä»£ç ï¼Œè¿è¡Œå®ƒï¼Œä¿®æ”¹å®ƒï¼Œç ´åå®ƒï¼Œä¿®å¤å®ƒ
2. **æé—®å’Œåˆ†äº«**ï¼šåœ¨ Discussions ä¸­æé—®ï¼Œåˆ†äº«ä½ çš„æ”¹è¿›
3. **ä¿æŒç®€æ´**ï¼šæ·»åŠ æ–°åŠŸèƒ½æ—¶ï¼Œé—®è‡ªå·±"è¿™çœŸçš„å¿…è¦å—ï¼Ÿ"
4. **äº«å—è¿‡ç¨‹**ï¼šè®­ç»ƒ LLM å¾ˆæœ‰è¶£ï¼Œäº«å—è¿™ä¸ªè¿‡ç¨‹ï¼

---

## é™„å½•

### A. ç›®å½•ç»“æ„é€ŸæŸ¥

```
nanochat/
â”œâ”€â”€ nanochat/              # æ ¸å¿ƒåº“
â”‚   â”œâ”€â”€ gpt.py            # â­ GPT æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ engine.py         # â­ æ¨ç†å¼•æ“
â”‚   â”œâ”€â”€ dataloader.py     # â­ æ•°æ®åŠ è½½
â”‚   â”œâ”€â”€ tokenizer.py      # â­ åˆ†è¯å™¨
â”‚   â”œâ”€â”€ muon.py           # Muon ä¼˜åŒ–å™¨
â”‚   â”œâ”€â”€ adamw.py          # AdamW ä¼˜åŒ–å™¨
â”‚   â”œâ”€â”€ checkpoint_manager.py  # æ£€æŸ¥ç‚¹ç®¡ç†
â”‚   â”œâ”€â”€ common.py         # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ configurator.py   # é…ç½®ç³»ç»Ÿ
â”‚   â”œâ”€â”€ dataset.py        # æ•°æ®ä¸‹è½½
â”‚   â”œâ”€â”€ core_eval.py      # CORE è¯„ä¼°
â”‚   â”œâ”€â”€ loss_eval.py      # æŸå¤±è¯„ä¼°
â”‚   â”œâ”€â”€ execution.py      # å·¥å…·æ‰§è¡Œ
â”‚   â”œâ”€â”€ report.py         # æŠ¥å‘Šç”Ÿæˆ
â”‚   â””â”€â”€ ui.html           # Web UI
â”œâ”€â”€ scripts/              # å¯æ‰§è¡Œè„šæœ¬
â”‚   â”œâ”€â”€ tok_train.py      # ğŸ“ åˆ†è¯å™¨è®­ç»ƒ
â”‚   â”œâ”€â”€ tok_eval.py       # ğŸ“ åˆ†è¯å™¨è¯„ä¼°
â”‚   â”œâ”€â”€ base_train.py     # ğŸš€ åŸºç¡€æ¨¡å‹è®­ç»ƒ
â”‚   â”œâ”€â”€ base_eval.py      # ğŸš€ åŸºç¡€æ¨¡å‹è¯„ä¼°
â”‚   â”œâ”€â”€ base_loss.py      # ğŸš€ åŸºç¡€æ¨¡å‹æŸå¤±
â”‚   â”œâ”€â”€ mid_train.py      # ğŸ’¬ ä¸­é—´è®­ç»ƒ
â”‚   â”œâ”€â”€ chat_sft.py       # ğŸ’¬ ç›‘ç£å¾®è°ƒ
â”‚   â”œâ”€â”€ chat_rl.py        # ğŸ¯ å¼ºåŒ–å­¦ä¹ 
â”‚   â”œâ”€â”€ chat_eval.py      # ğŸ’¬ èŠå¤©è¯„ä¼°
â”‚   â”œâ”€â”€ chat_cli.py       # ğŸ’» å‘½ä»¤è¡Œç•Œé¢
â”‚   â””â”€â”€ chat_web.py       # ğŸŒ Web ç•Œé¢
â”œâ”€â”€ tasks/                # è¯„ä¼°ä»»åŠ¡
â”‚   â”œâ”€â”€ common.py         # ä»»åŠ¡åŸºç±»
â”‚   â”œâ”€â”€ arc.py            # ARC ä»»åŠ¡
â”‚   â”œâ”€â”€ gsm8k.py          # æ•°å­¦ä»»åŠ¡
â”‚   â”œâ”€â”€ humaneval.py      # ä»£ç ä»»åŠ¡
â”‚   â”œâ”€â”€ mmlu.py           # MMLU ä»»åŠ¡
â”‚   â”œâ”€â”€ smoltalk.py       # å¯¹è¯ä»»åŠ¡
â”‚   â”œâ”€â”€ spellingbee.py    # æ‹¼å†™ä»»åŠ¡
â”‚   â””â”€â”€ customjson.py     # è‡ªå®šä¹‰ä»»åŠ¡
â”œâ”€â”€ rustbpe/              # Rust åˆ†è¯å™¨
â”œâ”€â”€ tests/                # æµ‹è¯•
â”œâ”€â”€ dev/                  # å¼€å‘å·¥å…·
â”œâ”€â”€ speedrun.sh           # âš¡ å¿«é€Ÿè®­ç»ƒè„šæœ¬
â”œâ”€â”€ run1000.sh            # ğŸ’° å®Œæ•´è®­ç»ƒè„šæœ¬
â””â”€â”€ pyproject.toml        # é¡¹ç›®é…ç½®
```

### B. å‘½ä»¤é€ŸæŸ¥è¡¨

```bash
# ============ ç¯å¢ƒè®¾ç½® ============
uv venv && source .venv/bin/activate
uv sync --extra gpu

# ============ è®­ç»ƒ ============
# åˆ†è¯å™¨
python -m scripts.tok_train --max_chars=2000000000

# åŸºç¡€æ¨¡å‹
torchrun --nproc_per_node=8 -m scripts.base_train -- --depth=20

# Midtraining
torchrun --nproc_per_node=8 -m scripts.mid_train

# SFT
torchrun --nproc_per_node=8 -m scripts.chat_sft

# RLï¼ˆå¯é€‰ï¼‰
torchrun --nproc_per_node=8 -m scripts.chat_rl

# ============ è¯„ä¼° ============
# åŸºç¡€æ¨¡å‹
torchrun --nproc_per_node=8 -m scripts.base_eval

# èŠå¤©æ¨¡å‹
torchrun --nproc_per_node=8 -m scripts.chat_eval -- -i sft

# ç‰¹å®šä»»åŠ¡
torchrun --nproc_per_node=8 -m scripts.chat_eval -- -i sft -a GSM8K

# ============ æ¨ç† ============
# CLI
python -m scripts.chat_cli
python -m scripts.chat_cli -p "é—®é¢˜"

# Web
python -m scripts.chat_web

# ============ å·¥å…· ============
# ä¸‹è½½æ•°æ®
python -m nanochat.dataset -n 8

# ç”ŸæˆæŠ¥å‘Š
python -m nanochat.report generate

# æµ‹è¯•
pytest tests/test_rustbpe.py -v
```

### C. é…ç½®å‚æ•°é€ŸæŸ¥

**base_train.py ä¸»è¦å‚æ•°**ï¼š

```python
--depth=20              # æ¨¡å‹æ·±åº¦ï¼ˆå±‚æ•°ï¼‰
--max_seq_len=2048      # åºåˆ—é•¿åº¦
--device_batch_size=32  # æ¯è®¾å¤‡æ‰¹æ¬¡å¤§å°
--total_batch_size=524288  # æ€»æ‰¹æ¬¡å¤§å°
--num_iterations=5000   # è®­ç»ƒæ­¥æ•°
--matrix_lr=0.02        # Muon å­¦ä¹ ç‡
--embedding_lr=0.2      # åµŒå…¥å­¦ä¹ ç‡
--eval_every=250        # è¯„ä¼°é¢‘ç‡
--run=dummy             # wandb è¿è¡Œå
```

**chat_sft.py ä¸»è¦å‚æ•°**ï¼š

```python
--source=mid            # æºæ¨¡å‹ï¼ˆbase/midï¼‰
--device_batch_size=4   # æ‰¹æ¬¡å¤§å°
--num_epochs=1          # è®­ç»ƒè½®æ•°
--matrix_lr=0.02        # å­¦ä¹ ç‡
--init_lr_frac=0.02     # åˆå§‹å­¦ä¹ ç‡æ¯”ä¾‹
--eval_every=100        # è¯„ä¼°é¢‘ç‡
```

### D. æ€§èƒ½åŸºå‡†

**d20 æ¨¡å‹ï¼ˆ561M å‚æ•°ï¼‰**ï¼š

```
è®­ç»ƒï¼š
- æ—¶é—´ï¼š2.5 å°æ—¶ï¼ˆ8XH100ï¼‰
- MFUï¼š~40%
- Tokens/secï¼š~200K

è¯„ä¼°ï¼š
- COREï¼š~0.22
- ARC-Easyï¼š~0.36
- ARC-Challengeï¼š~0.28
- GSM8Kï¼ˆSFTï¼‰ï¼š~0.05
- MMLUï¼š~0.31

æ¨ç†ï¼š
- Tokens/secï¼š~100ï¼ˆå•GPUï¼Œbatch=1ï¼‰
- å»¶è¿Ÿï¼š~10ms/token
```

**d26 æ¨¡å‹ï¼ˆ1.2B å‚æ•°ï¼‰**ï¼š

```
è®­ç»ƒï¼š
- æ—¶é—´ï¼š~10 å°æ—¶ï¼ˆ8XH100ï¼‰
- COREï¼š~0.26ï¼ˆè¶…è¶Š GPT-2ï¼‰
```

### E. èµ„æºé“¾æ¥

**å®˜æ–¹èµ„æº**ï¼š
- GitHubï¼šhttps://github.com/karpathy/nanochat
- Discussionsï¼šhttps://github.com/karpathy/nanochat/discussions
- Demoï¼šhttps://nanochat.karpathy.ai

**ç›¸å…³é¡¹ç›®**ï¼š
- nanoGPTï¼šhttps://github.com/karpathy/nanoGPT
- modded-nanoGPTï¼šhttps://github.com/KellerJordan/modded-nanogpt

**å­¦ä¹ èµ„æº**ï¼š
- LLM101n è¯¾ç¨‹ï¼šï¼ˆå¾…å‘å¸ƒï¼‰
- PyTorch æ–‡æ¡£ï¼šhttps://pytorch.org/docs
- Andrej Karpathy YouTubeï¼šhttps://youtube.com/@AndrejKarpathy

---

**æ–‡æ¡£ç»“æŸ**

*å¦‚æœ‰ç–‘é—®æˆ–å»ºè®®ï¼Œæ¬¢è¿åœ¨ GitHub Discussions ä¸­æå‡ºï¼*

*ç¥ä½ è®­ç»ƒæ„‰å¿«ï¼ğŸš€*

